{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananya2108/Deep-Learning-and-Data-Analytics-Lab-2025/blob/main/24MCS121_Experiment_9_Autoencoder_and_GAN_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experiment 9: Autoencoder and GAN implementation**\n",
        "\n",
        "## Abstract\n",
        "\n",
        "In medical imaging, noise and limited dataset sizes can hinder diagnostic performance. In this work, we propose a two-pronged deep learning framework: an advanced denoising autoencoder for removing noise from medical images, and a Generative Adversarial Network (GAN) to synthesize realistic images for data augmentation. The autoencoder leverages a multi-layer convolutional architecture with batch normalization and pooling to reconstruct clean images from noisy inputs. Concurrently, the GAN is designed to generate synthetic images that closely mimic real medical images, thus expanding the training data. Experimental results, including quantitative metrics such as Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index Measure (SSIM), as well as qualitative visualizations, demonstrate the effectiveness of the proposed methods. The framework shows promise for improving downstream tasks in medical image analysis.\n"
      ],
      "metadata": {
        "id": "l2dq2bTORIpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "Medical imaging is central to modern diagnostic processes, yet the quality of these images can be compromised by noise from various sources, such as sensor limitations and low-dose imaging protocols. Furthermore, the scarcity of annotated medical images limits the training of robust diagnostic models. To address these issues, this work integrates two deep learning techniques:\n",
        "- A **denoising autoencoder** designed to remove noise from images by learning a compact latent representation.\n",
        "- A **Generative Adversarial Network (GAN)** for synthesizing realistic images to augment the available dataset.\n",
        "This integrated approach not only improves image quality but also enriches the training data, potentially leading to enhanced performance in clinical applications.\n"
      ],
      "metadata": {
        "id": "3Ov4Lkc7RUSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Methodology\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s_Q7NxgARXUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Denoising Autoencoder\n",
        "\n",
        "The denoising autoencoder is designed to learn a compact latent representation of the medical images and reconstruct a noise-free version from a noisy input. The architecture comprises an encoder and a decoder:\n",
        "\n",
        "- **Encoder:**  \n",
        "  The encoder uses multiple convolutional layers with ReLU activation, batch normalization, and max pooling to gradually reduce the spatial dimensions of the input image. This helps the network capture the underlying structure and essential features of the image while discarding high-frequency noise.\n",
        "\n",
        "- **Decoder:**  \n",
        "  The decoder mirrors the encoder with upsampling layers and convolutional layers to reconstruct the image from the latent space. A sigmoid activation in the final layer ensures that the output pixel values are in the [0,1] range, matching the normalized input.\n",
        "\n",
        "The model is trained to minimize the Mean Squared Error (MSE) between the reconstructed image and the original clean image. Additional metrics such as Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) are used to quantitatively assess the quality of reconstruction."
      ],
      "metadata": {
        "id": "fodytF1jRbiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.2 Generative Adversarial Network (GAN) for Data Augmentation\n",
        "\n",
        "The GAN consists of two adversarial components:\n",
        "\n",
        "- **Generator:**  \n",
        "  The generator transforms a random noise vector into a synthetic medical image. It uses a series of transposed convolutional layers (Conv2DTranspose) along with batch normalization and LeakyReLU activations to upscale the noise into a full-resolution image. The output is produced with a tanh activation to yield pixel values in the range [-1,1].\n",
        "\n",
        "- **Discriminator:**  \n",
        "  The discriminator is a convolutional neural network that classifies images as real or fake. It employs convolutional layers with LeakyReLU activations and dropout for regularization. The discriminator outputs a single logit indicating the authenticity of the input image.\n",
        "\n",
        "The adversarial training setup pits the generator against the discriminator in a min-max game. The generator is optimized to produce images that can fool the discriminator, while the discriminator is trained to accurately distinguish between real and generated images. Label smoothing and a balanced update schedule (with multiple discriminator updates per generator update) are applied to stabilize training."
      ],
      "metadata": {
        "id": "wVjxEeniReVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 2.3 Experimental Setup\n",
        "\n",
        "For our experiments, we used three publicly available Kaggle datasets:\n",
        "- **Lung & Colon Cancer Histopathological Images:** Provided in the directory `/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets`.\n",
        "- **Brain Tumor MRI Dataset:** Loaded from `/kaggle/input/brain-tumor-mri-dataset/Training`.\n",
        "- **Chest X-ray Pneumonia Dataset:** Extracted from `/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train`.\n",
        "\n",
        "**Data Preprocessing:**  \n",
        "Each dataset is resized to 128Ã—128 pixels and normalized to the [0,1] range. For the autoencoder, Gaussian noise is added on-the-fly to create noisy input images, while the clean images serve as reconstruction targets.\n",
        "\n",
        "**Training Procedure:**  \n",
        "- **Autoencoder:**  \n",
        "  The advanced denoising autoencoder is trained using a Mean Squared Error (MSE) loss. An EarlyStopping callback is employed to prevent overfitting. The model is trained for up to 50 epochs with a batch size of 32.\n",
        "  \n",
        "- **GAN:**  \n",
        "  The GAN is trained using binary crossentropy loss with label smoothing applied to the discriminator's real labels. The training loop includes two discriminator updates for every generator update to maintain balance. A fixed noise vector is used to generate sample images at the end of each epoch for qualitative evaluation.\n",
        "\n",
        "**Hardware and Software:**  \n",
        "Experiments were conducted in a Kaggle Notebook environment with a GPU (e.g., NVIDIA T4). TensorFlow was used as the deep learning framework, leveraging its high-level Keras API for model development and training.\n",
        "\n",
        "**Evaluation Metrics:**  \n",
        "- **Mean Squared Error (MSE):** To quantify the reconstruction error of the autoencoder.\n",
        "- **Peak Signal-to-Noise Ratio (PSNR):** To measure the quality of denoised images.\n",
        "- **Structural Similarity Index Measure (SSIM):** To assess the structural similarity between the reconstructed and original images.\n",
        "- **Visual Inspection:** Generated samples from both the autoencoder and GAN are visually inspected for qualitative assessment.\n",
        "\n",
        "This comprehensive experimental setup ensures that the models are trained and evaluated rigorously, providing insights into both the quantitative performance and the qualitative visual quality of the denoising and augmentation processes."
      ],
      "metadata": {
        "id": "X2t-dcSKRgzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Code Implementation"
      ],
      "metadata": {
        "id": "exODJJ1gRkKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Auto encoders for image denoising on medical image  datasets :"
      ],
      "metadata": {
        "id": "ooMdRh8bRksa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable GPU memory growth (must run first, before any TF/Keras imports)\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Set memory growth to avoid allocating all GPU memory at once\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"Memory growth enabled for GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(\"Error setting memory growth:\", e)\n"
      ],
      "metadata": {
        "id": "S8W_hdwqRrsz",
        "outputId": "8e5bbeb6-3bbe-4e68-b2b8-fe86a42396e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory growth enabled for GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 2] Install required package kagglehub (if not installed already)\n",
        "!pip install kagglehub\n"
      ],
      "metadata": {
        "id": "Chtk991bRtxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries (all comments are inline)\n",
        "import numpy as np  # For numerical operations\n",
        "import tensorflow as tf  # TensorFlow for model building\n",
        "from tensorflow.keras import layers, models, losses, optimizers, callbacks  # Keras modules\n",
        "import matplotlib.pyplot as plt  # For plotting graphs and images\n",
        "import math  # For computing PSNR\n",
        "import os  # For file path operations\n",
        "import kagglehub  # For downloading Kaggle datasets\n",
        "import time\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "id": "PBWICAJlRy1G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}